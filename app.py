#!/usr/bin/env python3
"""
FastAPI service for AI-Manuals
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ POST /upload            â€“ add a PDF to Pinecone (returns doc_id)
â€¢ GET  /ingest/status     â€“ progress & ready flag while ingest runs
â€¢ POST /upload/metadata   â€“ store user-supplied doc_type / notes
â€¢ POST /chat              â€“ ask a question â†’ {"answer", "chunks_used"}
â€¢ POST /feedback          â€“ thumbs-up / thumbs-down (+ chunk IDs)
â€¢ GET  /feedback/summary  â€“ daily ðŸ‘ / ðŸ‘Ž counts
â€¢ GET  /feedback/chunks   â€“ hall-of-shame per chunk
â€¢ static /                â€“ tiny HTML/JS front-end
"""

from __future__ import annotations

import os
import tempfile
import uuid
from typing import Any, Dict, List, Optional

from fastapi import (
    BackgroundTasks,
    Depends,
    FastAPI,
    File,
    Form,
    HTTPException,
    UploadFile,
)
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from sqlalchemy import text

# â”€â”€â”€ local modules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from ingest_manual import ingest, pdf_to_chunks            # pre-size estimate
from qa_demo import chat                                   # now expects doc_type
from auth import require_api_key
from db import engine

# â”€â”€â”€ tunables (env-vars) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CHUNK_TOKENS: int = int(os.getenv("CHUNK_TOKENS", "800"))
OVERLAP: int      = int(os.getenv("OVERLAP", "150"))

# â”€â”€â”€ in-memory job table for ingest progress â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
JOBS: Dict[str, Dict[str, Any]] = {}

# â”€â”€â”€ FastAPI & CORS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI()

CORS_ORIGINS = os.getenv(
    "CORS_ALLOW_ORIGINS",
    "https://ai-manuals.onrender.com,http://localhost:5173,http://127.0.0.1:5173",
).split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=CORS_ORIGINS,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1)  Upload & ingest â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
def _ingest_and_cleanup(path: str, customer: str, doc_id: str) -> None:
    """Runs in background thread: ingest â†’ mark JOBS â†’ remove tmp."""
    def _update(done: int):
        if doc_id in JOBS:
            JOBS[doc_id]["done"] = done

    try:
        ingest(
            path,
            customer,
            CHUNK_TOKENS,
            OVERLAP,
            dry_run=False,
            progress_cb=_update,        # <â”€ new callback
        )
        JOBS[doc_id]["ready"] = True
        print(f"âœ… Ingest complete: {path}")
    except Exception as exc:
        JOBS.setdefault(doc_id, {})["error"] = str(exc)
        print(f"ðŸ›‘ Ingest failed: {exc}")
    finally:
        try:
            os.remove(path)
        except FileNotFoundError:
            pass


@app.post("/upload", dependencies=[Depends(require_api_key)])
async def upload_pdf(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    customer: str    = Form("demo01"),
):
    doc_id = uuid.uuid4().hex
    print(f"ðŸ“¥ Upload received: {file.filename} from {customer} (doc_id={doc_id})")

    tmp_path = os.path.join(tempfile.gettempdir(), f"{doc_id}_{file.filename}")
    with open(tmp_path, "wb") as h:
        h.write(await file.read())

    # cheap pre-parse for total chunks
    try:
        chunks, _ = pdf_to_chunks(tmp_path, CHUNK_TOKENS, OVERLAP)
        total = len(chunks)
    except Exception:
        total = 0

    JOBS[doc_id] = {"ready": False, "total": total, "done": 0, "meta": {}}
    background_tasks.add_task(_ingest_and_cleanup, tmp_path, customer, doc_id)
    return {"doc_id": doc_id, "status": "queued", "file": file.filename}


@app.get("/ingest/status", dependencies=[Depends(require_api_key)])
def ingest_status(doc_id: str):
    job = JOBS.get(doc_id)
    if not job:
        raise HTTPException(404, "doc_id not found")
    return job


@app.post("/upload/metadata", dependencies=[Depends(require_api_key)])
def add_metadata(
    doc_id: str   = Form(...),
    doc_type: str = Form(...),
    notes: str    = Form(""),
):
    JOBS.setdefault(doc_id, {}).setdefault("meta", {})
    JOBS[doc_id]["meta"].update({"doc_type": doc_type, "notes": notes[:200]})
    return {"ok": True}
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2)  Chat route â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
@app.post("/chat", dependencies=[Depends(require_api_key)])
async def ask(
    question: str  = Form(...),
    customer: str  = Form("demo01"),
    doc_type: str  = Form(""),            # â† NEW field from UI
):
    """Answer a question using the customerâ€™s Pinecone namespace."""
    result = chat(question, customer, doc_type)  # â† pass through
    if result.get("grounded") is False:
        print("âš ï¸  Fallback to GPT (not grounded)")
    return result
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3)  Feedback thumbs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
class FeedbackIn(BaseModel):
    customer: str
    question: str
    answer: str
    score: int
    chunks_used: Optional[List[str]] = None
    chunks: Optional[List[str]] = None


@app.post("/feedback", dependencies=[Depends(require_api_key)])
def add_feedback(data: FeedbackIn):
    if data.score not in (-1, 1):
        raise HTTPException(400, "score must be +1 or -1")

    chunk_ids = data.chunks_used or data.chunks or []
    print(f"ðŸ“ Feedback: {'ðŸ‘' if data.score == 1 else 'ðŸ‘Ž'} on {len(chunk_ids)} chunks")

    insert = text(
        """
        INSERT INTO feedback
            (customer, question, answer, score, chunks_used)
        VALUES
            (:customer, :question, :answer, :score, :chunks)
        """
    )
    with engine.begin() as conn:
        conn.execute(
            insert,
            {
                "customer": data.customer,
                "question": data.question,
                "answer":   data.answer,
                "score":    data.score,
                "chunks":   chunk_ids,
            },
        )
    return {"ok": True}
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4)  Feedback summaries â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
@app.get("/feedback/summary")
def feedback_summary(days: int = 7) -> List[Dict]:
    sql = text(
        f"""
        SELECT
            date_trunc('day', ts)::date AS day,
            SUM((score =  1)::int)      AS up,
            SUM((score = -1)::int)      AS down
        FROM feedback
        WHERE ts >= now() - INTERVAL '{days} days'
        GROUP BY day
        ORDER BY day;
        """
    )
    with engine.begin() as conn:
        rows = conn.execute(sql)
        return [
            {"day": r.day.isoformat(), "up": int(r.up), "down": int(r.down)}
            for r in rows
        ]
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5)  Worst-ranked chunks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
@app.get("/feedback/chunks")
def worst_chunks(days: int = 30, min_votes: int = 1, limit: int = 50) -> List[Dict]:
    sql = text(
        """
        SELECT
            unnest(chunks_used) AS chunk_id,
            COUNT(*)            AS total,
            SUM((score =  1)::int) AS up,
            SUM((score = -1)::int) AS down,
            ROUND(100.0 * SUM((score = 1)::int)::numeric
                  / NULLIF(COUNT(*), 0), 1) AS up_pct
        FROM feedback
        WHERE ts >= now() - INTERVAL :days || ' days'
        GROUP BY chunk_id
        HAVING COUNT(*) >= :min_votes
        ORDER BY up_pct ASC, total DESC
        LIMIT :limit;
        """
    )
    with engine.begin() as conn:
        rows = conn.execute(
            sql, {"days": days, "min_votes": min_votes, "limit": limit}
        )
        return [
            {
                "chunk_id": r.chunk_id,
                "total":    int(r.total),
                "up":       int(r.up),
                "down":     int(r.down),
                "up_pct":   float(r.up_pct) if r.up_pct is not None else None,
            }
            for r in rows
        ]
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

# â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6)  Serve static front-end â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
app.mount("/", StaticFiles(directory="web", html=True), name="web")
# â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
